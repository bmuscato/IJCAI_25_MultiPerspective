{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_json('xxx.csv')\n",
    "test=pd.read_json('xx.csv')\n",
    "dev=pd.read_json('xx.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_json_to_dataframe(data):\n",
    "    records = []\n",
    "\n",
    "    for key, value in data.items():\n",
    "        record = {\n",
    "            \"id\": key,\n",
    "            \"text\": json.loads(value.get(\"text\", \"{}\")),\n",
    "            \"annotation_task\": value.get(\"annotation task\"),\n",
    "            \"number_of_annotations\": value.get(\"number of annotations\"),\n",
    "            \"annotations\": value.get(\"annotations\"),\n",
    "            \"annotators\": value.get(\"annotators\"),\n",
    "            \"lang\": value.get(\"lang\"),\n",
    "            \"hard_label\": value.get(\"hard_label\"),\n",
    "            \"split\": value.get(\"split\"),\n",
    "            \"bot\": value.get(\"other_info\", {}).get(\"bot\"),\n",
    "            \"conversation_ids\": value.get(\"other_info\", {}).get(\"conversation_id(s)\"),\n",
    "        }\n",
    "\n",
    "       \n",
    "        record[\"soft_labels\"] = list(value.get(\"soft_label\", {}).values())\n",
    "\n",
    "       \n",
    "        for annotation_key, annotation_value in value.get(\"other_info\", {}).get(\"other_annotations\", {}).items():\n",
    "            record[f\"other_annotations_{annotation_key}\"] = annotation_value\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    " \n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "   \n",
    "    df = pd.concat([df.drop(\"text\", axis=1), df[\"text\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = transform_json_to_dataframe(train)\n",
    "df_test= transform_json_to_dataframe(test)\n",
    "df_val = transform_json_to_dataframe(dev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['prev_agent'] + ' ' + df_train['prev_user'] + ' ' + df_train['agent']\n",
    "\n",
    "df_test['text'] = df_test['prev_agent'] + ' ' + df_test['prev_user'] + ' ' + df_test['agent']\n",
    "\n",
    "df_val['text'] = df_val['prev_agent'] + ' ' + df_val['prev_user'] + ' ' + df_val['agent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['hard_label'] = pd.to_numeric(df_train['hard_label'], errors='coerce').fillna(0).astype(int)\n",
    "df_val['hard_label'] = pd.to_numeric(df_val['hard_label'], errors='coerce').fillna(0).astype(int)\n",
    "df_test['hard_label'] = pd.to_numeric(df_test['hard_label'], errors='coerce').fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def to_dataset(data):\n",
    "    if isinstance(data, pd.DataFrame):  \n",
    "        return Dataset.from_pandas(data)\n",
    "    return data  \n",
    "\n",
    "\n",
    "df_train, df_val, df_test = map(to_dataset, [df_train, df_val, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({'train': df_train, 'val': df_val, 'test': df_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-large'\n",
    "model_name_filename = model_name.replace(\"/\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(examples):\n",
    "\n",
    "    tokenized_inputs = tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
    "    tokenized_inputs['labels'] = examples['soft_labels']  \n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2398/2398 [00:00<00:00, 4707.41 examples/s]\n",
      "Map: 100%|██████████| 812/812 [00:00<00:00, 5636.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_tokenized = df_train.map(tokenize_func, batched = True)\n",
    "val_tokenized = df_val.map(tokenize_func, batched = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized.set_format('torch', columns =['input_ids', 'attention_mask', 'labels'])\n",
    "val_tokenized.set_format('torch', columns = ['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=len(train_tokenized['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"./multiclassification/{model_name_filename}/results/roberta_conv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "   \n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    \n",
    "    preds = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    \n",
    "\n",
    "    if labels.ndim > 1:\n",
    "        \n",
    "        true_labels = labels.argmax(axis=-1)\n",
    "    else:\n",
    "      \n",
    "        true_labels = labels\n",
    "    \n",
    "\n",
    "    pred_labels = preds.argmax(axis=-1)\n",
    "    \n",
    "\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    \n",
    "\n",
    "    f1_macro = f1_score(true_labels, pred_labels, average='macro')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'eval_f1': f1_macro,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \n",
    "        true_probabilities = inputs.pop(\"labels\")\n",
    "        \n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "       \n",
    "        true_probabilities = true_probabilities.to(logits.device)\n",
    "        \n",
    "       \n",
    "        loss= nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        \n",
    "        loss = loss(logits.squeeze(-1), true_probabilities)  \n",
    "        \n",
    "      \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/600 09:57 < 03:20, 0.75 it/s, Epoch 6/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.445100</td>\n",
       "      <td>0.460854</td>\n",
       "      <td>0.463318</td>\n",
       "      <td>0.863300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.442100</td>\n",
       "      <td>0.407213</td>\n",
       "      <td>0.463318</td>\n",
       "      <td>0.863300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>0.391652</td>\n",
       "      <td>0.480612</td>\n",
       "      <td>0.863300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.443300</td>\n",
       "      <td>0.403605</td>\n",
       "      <td>0.463318</td>\n",
       "      <td>0.863300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.470700</td>\n",
       "      <td>0.445375</td>\n",
       "      <td>0.463318</td>\n",
       "      <td>0.863300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.459300</td>\n",
       "      <td>0.445280</td>\n",
       "      <td>0.463318</td>\n",
       "      <td>0.863300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=450, training_loss=0.45302165349324547, metrics={'train_runtime': 599.8918, 'train_samples_per_second': 31.979, 'train_steps_per_second': 1.0, 'total_flos': 1.3408628455563264e+16, 'train_loss': 0.45302165349324547, 'epoch': 6.0})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "if isinstance(df_test, pd.DataFrame):\n",
    "    df_test = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'annotation_task', 'number_of_annotations', 'annotations', 'annotators', 'lang', 'hard_label', 'split', 'bot', 'conversation_ids', 'soft_labels', 'other_annotations_ableist', 'other_annotations_homophobic', 'other_annotations_intellectual', 'other_annotations_racist', 'other_annotations_sexist', 'other_annotations_sex_harassment', 'other_annotations_transphobic', 'other_annotations_target.generalised', 'other_annotations_target.individual', 'other_annotations_target.system', 'other_annotations_explicit', 'other_annotations_implicit', 'prev_agent', 'prev_user', 'agent', 'user', 'text'],\n",
       "    num_rows: 840\n",
       "})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 840/840 [00:00<00:00, 5511.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test = df_test.map(tokenize_func, batched=True)\n",
    "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import rel_entr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def kl_divergence(pred_probs, true_probs):\n",
    "   \n",
    "    pred_probs = np.clip(pred_probs, 1e-12, 1.0)\n",
    "    true_probs = np.clip(true_probs, 1e-12, 1.0)\n",
    "\n",
    "    \n",
    "    kl_div = np.sum(rel_entr(true_probs, pred_probs), axis=-1)  \n",
    "    return np.mean(kl_div) \n",
    "\n",
    "\n",
    "def js_divergence(pred_probs, true_probs):\n",
    "    \n",
    "    pred_probs = np.clip(pred_probs, 1e-12, 1.0)\n",
    "    true_probs = np.clip(true_probs, 1e-12, 1.0)\n",
    "\n",
    "   \n",
    "    js_div = jensenshannon(pred_probs, true_probs, base=2) ** 2  \n",
    "    return js_div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidences(df, model, tokenizer):\n",
    "    confidences = []\n",
    "    model.eval()  \n",
    "\n",
    "    for text in df['text']:\n",
    "       \n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=-1)  \n",
    "            confidences.append(probabilities.max().item())  \n",
    "    \n",
    "    df['confidence_scores'] = confidences\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "def predict(texts, model, tokenizer, device):\n",
    "    \n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    model.eval()  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()  \n",
    "        predicted_classes = np.argmax(probabilities, axis=-1)  \n",
    "        \n",
    "    return probabilities, predicted_classes\n",
    "\n",
    "\n",
    "test_df = df_test.to_pandas()\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(0, len(test_df), batch_size):\n",
    "    batch = test_df.iloc[i:i + batch_size]\n",
    "    batch_texts = batch['text'].tolist()\n",
    "    batch_labels = batch['soft_labels'].tolist()\n",
    "    \n",
    "    batch_probabilities, batch_predicted_classes = predict(batch_texts, model, tokenizer, device)\n",
    "    \n",
    "    all_predictions.extend(batch_probabilities)  \n",
    "    all_labels.extend(batch_labels) \n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "\n",
    "softmax_predictions = torch.nn.functional.softmax(torch.tensor(all_predictions), dim=-1).numpy()\n",
    "\n",
    "test_df['Predicted_Softmax_scores'] = softmax_predictions.tolist()  \n",
    "test_df['Predicted_class'] = np.argmax(softmax_predictions, axis=1) \n",
    "\n",
    "\n",
    "\n",
    "predicted_classes = np.argmax(all_predictions, axis=1) \n",
    "true_labels = np.argmax(all_labels, axis=1) \n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_classes)\n",
    "precision = precision_score(true_labels, predicted_classes, average='macro')\n",
    "recall = recall_score(true_labels, predicted_classes, average='macro')\n",
    "f1 = f1_score(true_labels, predicted_classes, average='macro')\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy * 100)\n",
    "print(\"Recall:\", recall * 100)\n",
    "print(\"Precision:\", precision * 100)\n",
    "print(\"F1:\", f1 * 100)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, predicted_classes))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_classes))\n",
    "\n",
    "reference_probs = np.full_like(softmax_predictions[0], 1 / len(softmax_predictions[0]))  \n",
    "js_divergence = np.mean([jensenshannon(prob, reference_probs) for prob in softmax_predictions])\n",
    "print(\"Jensen-Shannon Divergence:\", js_divergence)\n",
    "\n",
    "kl_div = np.mean([kl_divergence(prob, reference_probs) for prob in softmax_predictions])\n",
    "print(\"KL Divergence:\", kl_div)\n",
    "\n",
    "\n",
    "test_df = calculate_confidences(test_df, model, tokenizer)\n",
    "confidence_scores = test_df['confidence_scores']\n",
    "\n",
    "\n",
    "correct_confidence = np.mean([confidence for pred, true, confidence in zip(predicted_classes, true_labels, confidence_scores) if pred == true])\n",
    "incorrect_confidence = np.mean([confidence for pred, true, confidence in zip(predicted_classes, true_labels, confidence_scores) if pred != true])\n",
    "\n",
    "print(\"Average Confidence for Correct Predictions:\", correct_confidence * 100)\n",
    "print(\"Average Confidence for Incorrect Predictions:\", incorrect_confidence * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
